{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `import torch.nn as nn`: Imports the `torch.nn` module, which contains classes and functions to build neural networks. It is imported with an alias nn for convenience.\n",
    "2. `import torch.nn.functional as F`: Imports the `torch.nn.functional` module, which contains functions for building neural networks, especially for activation functions and other operations that donâ€™t require parameters (like ReLU, pooling, etc.). It's imported with an alias `F` for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # 1 input image channel (grayscale), 32 output channels/feature maps\n",
    "        # 5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "\n",
    "        # maxpool layer\n",
    "        # pool with kernel_size=2, stride=2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # fully-connected layer\n",
    "        # 32*4 input size to account for the downsampled image size after pooling\n",
    "        # num_classes outputs (for n_classes of image data)\n",
    "        self.fc1 = nn.Linear(32*4, n_classes)\n",
    "\n",
    "    # define the feedforward behavior\n",
    "    def forward(self, x):\n",
    "        # one conv/relu + pool layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "\n",
    "        # prep for linear layer by flattening the feature maps into feature vectors\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # linear layer \n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        # final output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `class Net(nn.Module):`: Defines a new class `Net`, which is a subclass of `nn.Module`. This is the base class for all neural network modules in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. `def __init__(self, n_classes):`: Defines the constructor method for the `Net` class, which is called when you create a new instance of the `Net` class. It takes `n_classes` as a parameter, which specifies the number of output classes for classification.\n",
    "5. `super(Net, self).__init__()`: Calls the constructor of the parent class (`nn.Module`). This is necessary to initialize the module properly, allowing you to use all the functionality provided by `nn.Module`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. `self.conv1 = nn.Conv2d(1, 32, 5)`: Defines the first convolutional layer (`conv1`). This layer takes a single input channel (grayscale image), produces 32 output channels (feature maps), and uses a 5x5 kernel for convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. `self.pool = nn.MaxPool2d(2, 2)`: Defines a max pooling layer (`pool`). This layer reduces the spatial dimensions of the feature maps by taking the maximum value over a 2x2 region with a stride of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. `self.fc1 = nn.Linear(32*4, n_classes)`: Defines a fully connected (linear) layer (`fc1`). This layer takes an input size of `32*4` (which accounts for the downsampled image size after pooling) and produces `n_classes` outputs, corresponding to the number of classes in the classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. `def forward(self, x):`: Defines the `forward` method, which specifies the forward pass of the network. This is where the input `x` is passed through the layers of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. `x = self.pool(F.relu(self.conv1(x)))`: Applies the first convolutional layer (`conv1`) to the input `x`, followed by a ReLU activation function, and then the max pooling layer (`pool`). This sequence extracts features from the input image, applies non-linearity, and downsamples the feature maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. `x = x.view(x.size(0), -1)`: Flattens the output of the pooling layer into a 2D tensor where the first dimension corresponds to the batch size, and the second dimension is the flattened feature vector. This is necessary to prepare the data for the fully connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. `x = F.relu(self.fc1(x))`: Applies the fully connected layer (`fc1`) to the flattened feature vector, followed by a ReLU activation function. This step combines the extracted features into the final classification output.\n",
    "13. `return x`: Returns the final output of the network, which consists of the predicted class scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=128, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n_classes = 20\n",
    "net = Net(n_classes)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. `n_classes = 20`: Defines the number of classes for the classification task (e.g., 20 classes).\n",
    "15. `net = Net(n_classes)`: Instantiates the `Net` class with the specified number of classes (`n_classes`). This creates a neural network model with the defined architecture.\n",
    "16. `print(net)`: Prints the architecture of the network, showing the layers and their configurations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
